{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c6c6400",
   "metadata": {},
   "source": [
    "# DERİN ÖĞRENME İLE MASKE TANIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44b176",
   "metadata": {},
   "source": [
    "# Veri Seti\n",
    "2863 maskeli,\n",
    "1743 maskesiz\n",
    "\n",
    "Veri seti adresi: https://github.com/cabani/MaskedFace-Net "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20665d4e",
   "metadata": {},
   "source": [
    "# 1) Gerekli Kütüphanelerin İmport İşlemleri ve Yüklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07848de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ebb4d",
   "metadata": {},
   "source": [
    "# 2) Veri Setinin Yüklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55930ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Non-Masked', 'Masked']\n",
    "\n",
    "REBUILD_DATA = True\n",
    "\n",
    "# Görüntülerin olduğu path bilgisinin tutulması\n",
    "if REBUILD_DATA: \n",
    "    data_path = Path('/content/drive/MyDrive/Dataset/self-built-masked-face-recognition-dataset')\n",
    "    maskPath = data_path/'AFDB_masked_face_dataset'\n",
    "    nonMaskPath = data_path/'AFDB_face_dataset'\n",
    "    maskDF = pd.DataFrame() \n",
    "    path_dirs = [ [maskPath,1],[nonMaskPath,0] ] #path and label\n",
    "    if not os.path.exists(data_path):\n",
    "        raise Exception(\"The data path doesn't exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c04a6",
   "metadata": {},
   "source": [
    "# 2.1) Image Size ve Label Etiket Değerlerinin Belirlenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskvNoMask():\n",
    "    IMG_SIZE = 100\n",
    "    LABELS = {'NON_MASKED': 0, 'MASKED': 1}\n",
    "    training_data = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        \"\"\"\n",
    "    Görüntülerin dosya konumunu açar ve ilgili görüntülerin label değerlerini belirler.\n",
    "    \n",
    "    Parametreler:\n",
    "    \n",
    "    self: https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/\n",
    "        \"\"\"\n",
    "        for data_dir, label in path_dirs:\n",
    "            print('Reading from: ',label)\n",
    "            for folder in tqdm(os.listdir(data_dir)):\n",
    "                folder_path = os.path.join(data_dir, folder)\n",
    "                for imgpath in os.listdir(folder_path):\n",
    "                    self.count += 1                       \n",
    "                    img_path = os.path.join(folder_path, imgpath)\n",
    "                    try:\n",
    "                        img = cv2.imread(img_path) #imread fonksiyonu yardımı ile görüntülerin okunması\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE,self.IMG_SIZE)) # görüntülerin yeniden boyutlandırılması\n",
    "                        self.training_data.append([np.array(img), label])\n",
    "                        self.count +=1 # eklenen görüntülerin saydırılması\n",
    "                        \n",
    "                        # Maskeli ve maskesiz görüntülerin sayılması ?\n",
    "                        if label == 1:\n",
    "                            self.LABELS['MASKED'] += 1\n",
    "                        if label == 0:\n",
    "                            self.LABELS['NON_MASKED'] +=1\n",
    "                    \n",
    "                    except:\n",
    "#                         raise Exception('error: {}'.format(img_path))\n",
    "                        pass\n",
    "            print(self.LABELS)\n",
    "#                         raise Exception('error occured while reading , {}'.format(os.path.join(maskPath, os.path.join(subject, imgPath))))\n",
    "                        \n",
    "        #veri setinde rastgelelik oluşturulması işlemi\n",
    "        np.random.shuffle(self.training_data)\n",
    "\n",
    "# Veri setinin fonksiyona verilmesi        \n",
    "if REBUILD_DATA:\n",
    "    maskvnomask = MaskvNoMask()\n",
    "    maskvnomask.make_training_data()\n",
    "    training_data = maskvnomask.training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c36a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntülere ait boyut bilgisi\n",
    "training_data[0][0].shape #training_data.shape, 'list' object has no attribute 'shape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntüye ait matris değerlerinin getirilmesi\n",
    "training_data[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b0240",
   "metadata": {},
   "source": [
    "# 3) Veri Setinden Örnekler Gösterilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Görüntünün imshow yardımı ile görselleştirilmesi\n",
    "plt.imshow(training_data[22][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a72a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntüye ait label değeri\n",
    "print(classes[training_data[1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e0817",
   "metadata": {},
   "source": [
    "# 4) Veri Kümesinin Oluşturulması ve Görselleştirilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c75c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "        \"\"\" Masked faces dataset\n",
    "        0 = 'no mask'\n",
    "        1 = 'mask'\n",
    "        \"\"\"\n",
    "        def __init__(self, train_data):\n",
    "            \"\"\"\n",
    "        Görselleri tensor formatına çevirir.\n",
    "    \n",
    "        Parametreler:\n",
    "    \n",
    "        self: https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/\n",
    "        \n",
    "        train_data : eğitim veri seti\n",
    "            \"\"\"\n",
    "            self.train_data = train_data\n",
    "            #https://pytorch.org/vision/stable/transforms.html\n",
    "            self.transformations = Compose([\n",
    "                ToTensor(),\n",
    "            ])\n",
    "        \n",
    "        def __getitem__(self, key): #for understanding get item = https://www.programmersought.com/article/98542425111/\n",
    "            \"\"\"\n",
    "        Tensor formatına çevrilen görüntülerin index bilgisini getirir.\n",
    "    \n",
    "        Parametreler:\n",
    "    \n",
    "        self: https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/\n",
    "        \n",
    "        key: train_data'da bulunan her bir görsel\n",
    "    \n",
    "        Return:\n",
    "    \n",
    "        self.transformations(self.train_data[key][0]): Görüntü\n",
    "    \n",
    "        torch.tensor(self.train_data[key][1]: Label bilgisi\n",
    "            \"\"\"\n",
    "            if isinstance(key, slice):\n",
    "                raise NotImplementedError('slicing is not supported')                    \n",
    "            return [\n",
    "                self.transformations(self.train_data[key][0]),\n",
    "                torch.tensor(self.train_data[key][1]) \n",
    "            ]\n",
    "        # magic method : https://stackoverflow.com/questions/2481421/difference-between-len-and-len\n",
    "        def __len__(self):\n",
    "            return len(self.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb293a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataset = MaskDataset(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(data):\n",
    "    \"\"\"\n",
    "    Tensor formatına çevrilen görüntülerin görselleştirilmesi.\n",
    "    \n",
    "    Parametreler:\n",
    "    \n",
    "    data : Görüntünün index bilgisi\n",
    "    \n",
    "    \"\"\"\n",
    "    img, label = data\n",
    "    print('Label: ', classes[int(label.item())], \"(\"+str(label.item())+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataset[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(myDataset[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = myDataset[36]\n",
    "print(img.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae438f",
   "metadata": {},
   "source": [
    "# 4.1) Train - Validation Split İşleminin Gerçekleştirilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 1000\n",
    "train_size = len(myDataset) - val_size\n",
    "\n",
    "train_ds, val_ds = torch.utils.data.random_split(myDataset, [train_size, val_size])#train_test_split\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e3718",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(val_ds[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b9efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loader açıklaması \n",
    "#Veri setinin mini gruplara ayrılması\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size*2, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff693d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    \"\"\"\n",
    "    Veri setinden örnek görüntüleri görselleştirir.\n",
    "    \n",
    "    Parametreler:\n",
    "    \n",
    "    dl: Görüntü\n",
    "    \"\"\"\n",
    "    \n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb33f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e870be",
   "metadata": {},
   "source": [
    "# 5) Optimizasyon ve Değerlendirme Metriklerinin Ayarlanması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Accuracy değerini hesaplar\n",
    "    \n",
    "    Parametreler:\n",
    "    \n",
    "    outputs: Tahminlenen görüntüler\n",
    "    labels: Etiket değerleri\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    torch.tensor(torch.sum(preds == labels).item() / len(preds)) : (Tahmin edilen label değerleri = görüntüye ait label değerleri) / Tüm tahminler' in toplamı\n",
    "    \"\"\"\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd633e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"\n",
    "        Modele ait loss değerini hesaplar.\n",
    "        \n",
    "        Parametreler:\n",
    "        \n",
    "        self: https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/\n",
    "        \n",
    "        batch: küçük veri grubu\n",
    "        \n",
    "        Return:\n",
    "        \n",
    "        loss: hata değerlendirme metriği\n",
    "        \"\"\"\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.long()) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"\n",
    "        Modele ait val_loss ve val_acc değerini hesaplar.\n",
    "        \n",
    "        Parametreler:\n",
    "        \n",
    "        self: https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/\n",
    "        \n",
    "        batch: küçük veri grubu\n",
    "        \n",
    "        Return:\n",
    "        \n",
    "        val_loss: \n",
    "        \n",
    "        val_acc :\n",
    "        \n",
    "        loss.detach() -> https://stackoverflow.com/questions/56816241/difference-between-detach-and-with-torch-nograd-in-pytorch\n",
    "        \n",
    "        \"\"\"\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels.long())   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        Küçük veri gruplarının val_loss ve val_acc değerlerinin ortalamasını hesaplar.\n",
    "        \n",
    "        Parametreler:\n",
    "        \n",
    "        self: https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/\n",
    "        \n",
    "        outputs: Tahminlenen görüntüler\n",
    "        \n",
    "        Return:\n",
    "        \n",
    "        val_loss: \n",
    "        \n",
    "        val_acc :\n",
    "        \n",
    "        item() -> https://www.programiz.com/python-programming/methods/dictionary/items\n",
    "        \"\"\"\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        \"\"\"\n",
    "        Hesaplanan train_loss,val_loss ve val_acc değerlerini bastırır.\n",
    "        \n",
    "        Parametreler:\n",
    "        \n",
    "        self: https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/\n",
    "        \n",
    "        epoch: Epoch sayısı, model eğitilirken verilerin modelden kaç kez geçiş yapacağını belirtir.\n",
    "        \n",
    "        result: Sonuç\n",
    "        \"\"\"\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "    def predict():\n",
    "        \"\"\"\n",
    "        Tahmin değerlerinden iki sınıf arasında max olan değeri alır.\n",
    "        \"\"\"\n",
    "        pred = model(img)\n",
    "        _, preds = torch.max(pred, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49489e3d",
   "metadata": {},
   "source": [
    "# 6) Modelleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b276722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDetection(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 100, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(100, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(160000, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        \"\"\"\n",
    "        forward method : https://discuss.pytorch.org/t/forward-method-call-for-weight-training/84314\n",
    "        \"\"\"\n",
    "        return self.network(xb) # xb = weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDetection1(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(80000, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2))\n",
    "        \n",
    "            \n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb) # xb = weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641c9db",
   "metadata": {},
   "source": [
    "# 6.2) Ekran Kartı Ayarlarının Yapılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea71b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim esnasında ekran kartının aktif olup olmadığının kontrol edilmesi \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521afe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"\n",
    "    Ekran kartı kontrollerini gerçekleştirir.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea270499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekran kartı bilgisi\n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"\n",
    "    Görüntüye ait tensor değerlerini ekran kartına aktarır.\n",
    "    \n",
    "    Parametreler:\n",
    "    \n",
    "    data: Tensor formatına çevrilmiş görüntüler\n",
    "    \n",
    "    device: Ekran kartı\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    device: Ekran kartı\n",
    "    non_blocking -> https://jovian.ai/forum/t/purpose-of-non-blocking-true-in-tensor-to/14760\n",
    "    \"\"\"\n",
    "    #move tensors to device\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c598ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntünün boyut bilgisini bastırır.\n",
    "\n",
    "for images, labels in train_dl:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af672112",
   "metadata": {},
   "source": [
    "# 6.3) Veri Setinin Ekran Kartına Aktarılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0cb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    #move data to a device\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        #Yield a batch of data after moving it to device\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        #Number of batchs\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ve Validation setlerinin aktarılması\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb = Ekran kartının çalışma bilgisi\n",
    "# yb = mini veri grubuna (batch_size) ait görüntülerin label değerleri\n",
    "for xb, yb in val_dl:\n",
    "    print('xb.device:', xb.device)\n",
    "    print('yb:', yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a24398",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    \"\"\"\n",
    "    https://discuss.pytorch.org/t/model-train-and-model-eval-vs-model-and-model-eval/5744\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    \"\"\"\n",
    "    \n",
    "    Modeli eğitir\n",
    "    \n",
    "    \n",
    "    Parametreler : \n",
    "    \n",
    "    epochs: Epoch sayısı, model eğitilirken verilerin modelden kaç kez geçiş yapacağını belirtir.\n",
    "    \n",
    "    lr: Öğrenme oranı\n",
    "    \n",
    "    model.parameters: Moel parametreleri\n",
    "    \n",
    "    train_loader: Eğitim veri seti \n",
    "    \n",
    "    val_loader: Validasyon veri seti \n",
    "    \n",
    "    opt_func: Optimizasyon Fonksiyonu\n",
    "    \n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    history: Modele ağit eğitim verileri\n",
    "    \"\"\"\n",
    "    history = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    for epoch in range(epochs): \n",
    "        print('epoch: ', epoch)\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (on GPU)\n",
    "model = MaskDetection1()\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ağırlıklarının kaydedilmesi\n",
    "checkpoint_path = os.path.join(os.getcwd(), \"checkpoints\")\n",
    "torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2163b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [evaluate(model, val_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=4\n",
    "history = fit(epoch, 1e-3, model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cb86b",
   "metadata": {},
   "source": [
    "# 6.4) Sonuçların Görselleştirilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    \"\"\"\n",
    "    Modele ait Validation Loss grafiğini çizdirir.\n",
    "    \n",
    "    Parametreler:\n",
    "    \n",
    "    history: Modele ağit eğitim verileri\n",
    "    \"\"\"\n",
    "    losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(losses, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Validation Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a58233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    \"\"\"\n",
    "    Modele ait Validation Accuracy grafiğini çizdirir.\n",
    "    \n",
    "    Parametreler:\n",
    "    \n",
    "    history: Modele ağit eğitim verileri\n",
    "    \"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Validation Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb672213",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096434ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f524d",
   "metadata": {},
   "source": [
    "# 7) Model Başarı Değerlendirme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45535e",
   "metadata": {},
   "source": [
    "# 7.1) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9cb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(val_dl):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c00685",
   "metadata": {},
   "source": [
    "# 8) Modelin Test Edilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08223116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "def singleImage(path, label= None, show= False):\n",
    "    img = cv2.imread(path)\n",
    "    assert img is not None,\"Immage wasn't read properly\"\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "    img = torch.from_numpy(img)\n",
    "    img = img.permute((2, 0,1)) # model expects image to be of shape [3, 100, 100]\n",
    "    img = img.unsqueeze(dim=0).float() # convert single image to batch [1, 3, 100, 100]\n",
    "    img = img.to('cuda') # Using the same device as the model\n",
    "    pred = model(img)\n",
    "    _, preds = torch.max(pred, dim=1)\n",
    "    print(classes[preds.item()])\n",
    "    #plt.imshow(img.squeeze(dim=0).permute((1,2,0)).to('cpu'))\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(mpimg.imread(path))\n",
    "        print(\"the image is :\" + classes[preds.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleImage('/content/drive/MyDrive/Dataset/self-built-masked-face-recognition-dataset/AFDB_face_dataset/hedujuan/1_0_hedujuan_0134.jpg', show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
